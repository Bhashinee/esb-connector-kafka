# Configuring Kafka Operations

To use the Kafka connector, download and install [Apache Kafka](http://kafka.apache.org/downloads.html).

>The recommended version is [kafka](https://www.apache.org/dyn/closer.cgi?path=/kafka/0.11.0.0/kafka_2.12-0.11.0.0.tgz). For all available versions of Kafka that you can download, see https://kafka.apache.org/downloads.
 Recommended Java version is 1.8

To configure the Kafka connector, copy the following client libraries from the <KAFKA_HOME>/lib directory to the <ESB_HOME>/repository/components/lib directory.

* [kafka_2.12-0.11.0.0.jar](https://mvnrepository.com/artifact/org.apache.kafka/kafka_2.12/0.11.0.0)
* [kafka-clients-0.11.0.0.jar](https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients/0.11.0.0)
* [Metrics-core-3.2.2.jar](https://mvnrepository.com/artifact/io.dropwizard.metrics/metrics-core/3.2.2)
* [Scala-library-2.12.2.jar](https://mvnrepository.com/artifact/org.scala-lang/scala-library/2.12.2)
* [Zkclient-0.10.jar](https://mvnrepository.com/artifact/com.101tec/zkclient/0.10)
* [zookeeper-3.4.10.jar](https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper/3.4.10)

To use the Kafka connector, add the element<kafkaTransport.init> in your configuration before carrying out any other 
Kafka operation 
[with security](https://docs.wso2.com/display/ESBCONNECTORS/Configuring+Kafka_2.12-0.11.0.0+Operations#ConfiguringKafka_2.12-0.11.0.0Operations-withSecu) or [without security](https://docs.wso2.com/display/ESBCONNECTORS/Configuring+Kafka_2.12-0.11.0.0+Operations#ConfiguringKafka_2.12-0.11.0.0Operations-withoutSecurity). 

##Enabling security

For detailed information on how to enable TLS authentication for the Kafka broker, producer and consumer, see 
[Enabling Security for the Kafka Connector and Inbound Endpoint](https://docs.wso2.com/display/ESBCONNECTORS/Enabling+Security+for+the+Kafka+Connector+and+Inbound+Endpoint).

Following is a sample configuration to create a producer without security.

**init**

````xml
    <kafkaTransport.init>
        <bootstrapServers>localhost:9092</bootstrapServers>
        <keySerializerClass>org.apache.kafka.common.serialization.StringSerializer</keySerializerClass>
        <valueSerializerClass>org.apache.kafka.common.serialization.StringSerializer</valueSerializerClass>
    </kafkaTransport.init>
    
````


> **security** : There is an additional feature for security can found in Kafka version 0.9.0.0 and above can be 
configured via the 
  element<kafkaTransport.init> as follows.


Following is a sample configuration to create a producer with security.

**init with security**

````xml
<kafkaTransport.init>
     <bootstrapServers>localhost:9093</bootstrapServers>
     <keySerializerClass>org.apache.kafka.common.serialization.StringSerializer</keySerializerClass>
     <valueSerializerClass>org.apache.kafka.common.serialization.StringSerializer</valueSerializerClass>
     <securityProtocol>SSL</securityProtocol>
     <sslTruststoreLocation>/home/hariprasath/Desktop/kafkaNewJira/certKafka/kafka.server.truststore.jks</sslTruststoreLocation>
     <sslTruststorePassword>test1234</sslTruststorePassword>
     <sslKeystoreLocation>/home/hariprasath/Desktop/kafkaNewJira/certKafka/kafka.server.keystore.jks</sslKeystoreLocation>
     <sslKeystorePassword>test1234</sslKeystorePassword>
     <sslKeyPassword>test1234</sslKeyPassword>
 </kafkaTransport.init>

````

**Properties**
* bootstrapServers : Required - The Kafka brokers listed as host1:port1, host2:port2.
* keySerializerClass : Required - The serializer class for the key that implements the serializer interface.
* valueSerializerClass : Required - The serializer class for value that implements the serializer interface.
* acks : The number of acknowledgments that the producer requires the leader to have received before considering a 
request complete.
* bufferMemory : The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
* compressionType: The compression type for all data generated by the producer.
* retries : Set a required value if you want automatic retry to take place when a request fails. Setting a value 
greater than zero causes the client to resend any record for which send fails with a potentially transient error.
* sslKeyPassword : The password of the private key in the key store file. Setting this for the client is optional.
* sslKeystoreLocation : The location of the key store file. Setting this for the client is optional and you can set 
this when you want to have two-way authentication for the client.
* sslKeystorePassword : The store password for the key store file. Setting this for the client is optional and you 
only need to set it if ssl.keystore.location is configured.
* sslTruststoreLocation : The location of the trust store file.
* sslTruststorePassword : The password for the trust store file.
* batchSize : Specify how many records the producer should batch together whenever multiple records are being sent to 
the same partition.
* clientId : The client identifier that you should pass to the server when making requests.
connectionsMaxIdleTime : The duration after which idle connections should be closed. The duration should be in milliseconds.
* lingerTime : The time span to wait before sending a record. This should be in milliseconds. Setting this property is
 useful if you want the client to reduce the number of requests sent when the load is moderate. (ie.,This adds a small amount of artificial delay rather than immediately sending out a record. Therefore, the producer waits up to the given delay to allow other records to be sent so that the sends can be batched together.
* maxBlockTime : The maximum time that KafkaProducer.send() method and the KafkaProducer.partitionsFor() method can 
block. Specify the time in milliseconds.
* maxRequestSize : The maximum size of a request in bytes.
* partitionerClass : The partitioner class that implements the Partitioner interface.
* receiveBufferBytes : The size of the TCP receive buffer (SO_RCVBUF) to use when reading data.
* requestTimeout : The maximum amount of time that a client can wait for the server to respond to a request. Specify 
the time  in milliseconds.
* saslJaasConfig : JAAS login context parameters for SASL connections in the format used by JAAS configuration files. 
* saslKerberosServiceName : The Kerberos principal name that Kafka runs as.
* securityProtocol : The protocol used to communicate with brokers.
* sendBufferBytes : The size of the TCP send buffer (SO_SNDBUF) to use when sending data.
* sslEnabledProtocols : The list of protocols enabled for SSL connections.
* sslKeystoreType : The file format of the key store file. Setting this for the client is optional.
* sslProtocol : The SSL protocol used to generate the SSLContext.
* sslProvider : The name of the security provider used for SSL connections. The default value is the default security 
provider of the JVM.
* sslTruststoreType : The file format of the trust store file.
* timeout : The maximum amount of time that the server can wait for acknowledgments from followers to meet the 
* acknowledgment requirements that the producer has specified with  acks  configuration. Specify the time  in 
milliseconds.
* blockOnBufferFull : Set this to true if you want to stop accepting new records when the memory buffer is full. 
However, if you have a scenario where blocking is not desirable, you can set this property to false, which causes the producer to throw an exception if a recrord is sent to the memory buffer when it is full.
* maxInFlightRequestsPerConnection : The maximum number of unacknowledged requests that the client can send via a 
single connection before blocking.
* metadataFetchTimeout : The maximum amount of time to block and wait for the metadata fetch to succeed before 
throwing an exception to the client. Specify the time in milliseconds.
* metadataMaxAge : The period of time in milliseconds after which you should force a refresh of metadata even if there
 was no partition leadership changes to proactively discover any new brokers or partitions. Specify the time in milliseconds.
* metricReporters : A list of classes to use as metrics reporters.
* metricsNumSamples : The number of samples maintained to compute metrics.
* metricsSampleWindow : The window of time in milliseconds that a metrics sample is computed over.
* reconnectBackoff : The amount of time to wait before attempting to reconnect to a given host.
* retryBackoff : The amount of time to wait before attempting to retry a failed request to a given topic partition. 
Specify the time in milliseconds.
* saslKerberosKinitCmd : The kerberos kinit command path.
* saslKerberosMinTimeBeforeRelogin : Login thread sleep time between refresh attempts. Specify the time in milliseconds.
* saslKerberosTicketRenewJitter : Percentage of random jitter added to the renewal time.
* saslKerberosTicketRenewWindowFactor : The login thread sleeps until the specified window factor of time from the 
last refresh to the ticket's expiry is reached, after which it will try to renew the ticket.
* sslCipherSuites : A list of cipher suites.
* sslEndpointIdentificationAlgorithm : The endpoint identification algorithm to validate the server hostname using 
server certificate.
* sslKeymanagerAlgorithm : The algorithm used by key manager factory for SSL connections. The default value is the key
 manager factory algorithm configured for the Java Virtual Machine.
* sslSecureRandomImplementation : The SecureRandom PRNG implementation to use for SSL cryptography operations.
* sslTrustmanagerAlgorithm : The algorithm used by trust manager factory for SSL connections. The default value is the
 trust manager factory algorithm configured for the Java Virtual Machine.
* maxPoolSize : The maximum number of message requests that can share the Kafka connection.

**Performance tuning tip**  
For better throughput, configure the <maxPoolSize> parameter as follows in the <init> configuration:
````
<maxPoolSize>20</maxPoolSize>
````
If you do not specify the maxPoolSizeparameter in the configuration, a Kafka connection is created for each message request.

Now that you have connected to Kafka, you can start publishing messages to Kafka brokers. For more information, see 
[Publishing Messages using Kafka](publishmessage.md).